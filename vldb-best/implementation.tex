\section{Implementation}\label{sec:implementation}

\subsection{Formal verification}

We have formalized and verified all the definitions, lemmas,
propositions, theorems, and examples in this paper using the Lean
theorem prover; we make these proofs available at~\cite{dbsp-theory}.
The formalization builds on mathlib~\cite{mathlib2020}, which provides
support for groups and functions with finite support (modeling
\zrs). We believe the simplicity of \dbsp enabled completing these
proofs in relatively few lines of Lean code (5K) and keeping a close
correspondence between the paper proofs in~\cite{tr} and Lean.  The
existence of the proofs bolsters our confidence in the feasibility of
a practical implementation.

\subsection{The \dbsp Rust runtime}

We have built an implementation of \dbsp as part of an open-source
project with an MIT license~\cite{dbsp-crate}\footnote{We recommend
getting the latest version of the code from the source
repository~\cite{dbsp-repo}, because the code depends on a few changes
to other repositories which haven't been merged yet.}.  The
implementation consists of a Rust library and runtime.  The library
provides APIs for basic algebraic data types: such as groups, finite
maps, \zr, indexed \zr.  A separate circuit construction API allows
users to create \dbsp circuits by placing operator nodes
(corresponding to boxes in our diagrams) and connecting them with
streams, which correspond to the arrows in our diagrams.  The library
provides a rich library of more than 70 pre-built generic operators
for integration, differentiation, delay, nested integration and
differentiation, and basic \zr incremental operators, corresponding to
plus, negation, grouping, joining, semi-joins, anti-joins, temporal
joins, primitive aggregates, generic aggregates (fold), $\distinct$,
flatmap, window aggregates, etc.

For iterative computations the library provides the $\delta$ operator
and an operator that generalizes $\int$ by terminating iteration when
all the operators in the corresponding circuit cycle have reached a
fixed point.  The low level library allows users to construct
incremental circuits manually by stitching together incremental and
non-incremental versions of primitive operators.

The library also provides many ``helper'' operators that are used by
the query optimizer in the implementation of some classes of streaming
queries, e.g., for state garbage-collection.

Upsert operators.

\subsection{Parallelization and Scale-out}

The library supports data-parallel multicore evaluation of circuits
using a natural sharding strategy.

\subsection{State management}

Incremental computation is not free.  It is in fact a trade-off
between time and space.  While many incremental database operations
are ``stateless'', some important classes of database operations,
including joins, ``distinct'', and group-by-aggregate\footnote{The
``makeset'' part of the aggregate} can be implemented only using
additional storage the form of various \emph{indexes}.  In \dbsp
circuits these indexes appear in the form of integral operators $\I$.
The size of these indexes is proportional to the size of the total
data in the input relations of these operators (and not just to the
size of the changes) --- and thus can even exceed the size of the
original database.

In the \dbsp theoretical model the state is stored in fact in delay
operators $\zm$ (and $\lift{\zm}$).  All other operators are in fact
stateles.

When considering performance, linear operators are essentially free.
The performance of a \dbsp program under high load is essentially
bounded by the performance of the indexes.

There are two main operations provided by an index:
\begin{itemize}
\item merging an existing (large) index with a new (smaller) change
\item lookup a (small) set of values in the collection by key
\end{itemize}

The implementation for indexes is essentially a Log-Structured Merge
Tree~\cite{oneil-ai96} which is spilled to secondary storage.

TODO: the LSM data structure, storage organization

\subsubsection{Checkpointing and fault-tolerance}

The state in delay operators is the only state that needs to be
persisted, checkpointed, or migrated to make \dbsp computations
fault-tolerant.

TODO

\subsection{SQL compiler}

We have also built a SQL to \dbsp compiler, which translates standard
SQL queries into \dbsp circuits.  The compiler implements
Algorithm~\ref{algorithm-inc}, to generate a streaming version of any
SQL query.  The compiler is open-source~\cite{sql-to-dbsp-compiler}
with an MIT license.  The compiler front-end parser, and the plan
generator are based on the Apache Calcite~\cite{begoli-icmd18}
infrastructure.  The compiler inherits some of the strengths (and
limitations) of Calcite.  For example, Calcite is used to decorrelate
queries into joins, but the decorrelator is based on heuristics.

\textbf{Plan quality.}A relational algebra query can be implemented
by multiple plans, each with a different data-dependent cost.  The
input of Algorithm~\ref{algorithm-inc} is a non-incremental query
plan, produced by a query planner.  The algorithm produces an
incremental plan that is ``similar'' to the input plan.

Standard query planners use cost-based heuristics and data statistics
to optimize plans.  A generic IVM planner does not have this luxury,
since the plan must be generated \emph{before} any data has been fed
to the query.  Nevertheless, all standard query optimization
techniques, perhaps based on historical statistics, can be used to
generate the query plan that is supplied to our Algorithm.

The compiler is mature enough to pass all 7 million SQL Logic
Tests~\cite{sqllogictest}.  The compiler handles all aspects of SQL,
including NULLs, ternary logic, grouping, aggregation, multiset
queries, outer joins, window queries, etc.  The compiler does not yet
support recursive queries.

\subsection{Streaming SQL extensions}

TODO?

\subsection{Interacting with the outside world}

As it was pointed out many years ago~\cite{labio-vldb00}, database
systems are not designed to interact well with external IVM systems.
We provide a a variety of adapters for interacting with external data
sources, both as inputs and outputs (e.g., Kafka, CSV, JSON,
DataFrames, Delta Lake, Debezium, etc.).  The input adapters receive
data from external sources, convert it into \zrs, and feed it to the
circuits.  The output adapters receive data from the circuit output
and send it to a downstream consumer in a suitable format.

